{
    "model_name": "ensemble",
    "model_params": {
        "models": {
            "conv1d": {
                "input_embedding_dim": 128,
                "output_embedding_dim": 512,
                "layer_params": [
                    [
                        "residual_block",
                        {
                            "layer_params": [
                                [ "conv", { "in_channels": 128, "out_channels": 128, "padding": "same", "kernel_size": 5 } ],
                                [ "conv", { "in_channels": 128, "out_channels": 128, "padding": "same", "kernel_size": 3 } ],
                                [ "batch_norm", { "num_features": 128 }],
                                [ "relu", {} ]
                            ]
                        }
                    ],
                    [ "conv", { "in_channels": 128, "out_channels": 256, "kernel_size": 5 } ],
                    [ "batch_norm", { "num_features": 256 }],
                    [ "max_pool", { "kernel_size": 2 } ],
                    [ "dropout", { "p": 0.3 } ],
                    
                    [
                        "residual_block",
                        {
                            "layer_params": [
                                [ "conv", { "in_channels": 256, "out_channels": 256, "padding": "same", "kernel_size": 5 } ],
                                [ "conv", { "in_channels": 256, "out_channels": 256, "padding": "same", "kernel_size": 3 } ],
                                [ "batch_norm", { "num_features": 256 }],
                                [ "relu", {} ]
                            ]
                        }
                    ],
                    [ "conv", { "in_channels": 256, "out_channels": 512, "kernel_size": 5 } ],
                    [ "batch_norm", { "num_features": 512 }],
                    [ "max_pool", { "kernel_size": 2 } ],
                    [ "dropout", { "p": 0.2 } ]
                ]
            },
            "pretrained_transformer": {
                "transformer_model": "maadm-nlp-group-b/maadm-nlp-pan23-task2-roberta-base-finetuned",
                "transformer_reduction": "cls",
                "hidden_dropout_prob": 0.0,
                "token_env_file": ".env"
            }
        }
    },
    "classification_head_params": {
        "dropout_p": 0.2,
        "ff_dim": 2048
    },
    "default_train_params": {
        "data_module_params": {
            "batch_size": 32,
            "max_len": 512,
            "tokenizer": "roberta-base"
        },
        "optimizer_params": {
            "lr": 0.00001
        },
        "trainer_params": {
            "precision": "16-mixed",
            "max_epochs": 10,
            "enable_checkpointing": true,
            "accelerator": "cuda",
            "devices": 1
        },
        "unfrozen_layers": 0
    },
    "@task2_override": {
        "data_module_params": {
            "data_path": "data/pan23/transformed/task2"
        },
        "trainer_params": {
            "default_root_dir": "out/roberta-base-ensemble/finetuned/task2",
            "val_check_interval": 0.5
        }
    },
    "@task1_override": { "skip": true },
    "@task3_override": { "skip": true }
}