{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PAN23 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataframe(task, set_type):\n",
    "    path = f\"./pan23-data/pan23-multi-author-analysis-dataset{task}/pan23-multi-author-analysis-dataset{task}-{set_type}/\"\n",
    "    filenames = os.listdir(path)\n",
    "\n",
    "    lines_by_id = dict()\n",
    "    truths_by_id = dict()\n",
    "\n",
    "    for filename in filenames:\n",
    "        is_truth = filename.startswith(\"truth\")\n",
    "        problem_id = re.search(r\"\\d+\", filename).group(0)\n",
    "        filepath = os.path.join(path, filename)\n",
    "\n",
    "        with open(filepath) as f:\n",
    "            if is_truth is True:\n",
    "                truths_by_id[problem_id] = json.load(f)[\"changes\"]\n",
    "            else:\n",
    "                lines_by_id[problem_id] = f.readlines()\n",
    "\n",
    "    df_dict = dict(id=[], text1=[], text2=[], label=[])\n",
    "    for problem_id in lines_by_id.keys():\n",
    "        lines = lines_by_id[problem_id]\n",
    "        truths = truths_by_id[problem_id]\n",
    "        for text1, text2, label in zip(lines, lines[1:], truths):\n",
    "            df_dict[\"id\"].append(problem_id)\n",
    "            df_dict[\"text1\"].append(text1)\n",
    "            df_dict[\"text2\"].append(text2)\n",
    "            df_dict[\"label\"].append(label)\n",
    "\n",
    "    return pd.DataFrame.from_dict(df_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for task in range(1, 4):\n",
    "    for set_type in [\"train\", \"validation\"]:\n",
    "        df = get_dataframe(task, set_type)\n",
    "        df.to_csv(f\"./data/pan23-task{task}-{set_type}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Blog data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\n",
    "    \"blogtext/blogtext.csv\",\n",
    "    usecols=[\"id\", \"text\"],\n",
    "    dtype={\"id\": \"category\", \"text\": \"string\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df[\"text\"].str.len() >= 200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1682400/2258154874.py:2: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  df = df.groupby(\"id\").filter(lambda x: len(x) >= 2)\n"
     ]
    }
   ],
   "source": [
    "# remove ids with counts less than 2\n",
    "df = df.groupby(\"id\").filter(lambda x: len(x) >= 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dict = dict()\n",
    "for author_id, text in zip(df[\"id\"], df[\"text\"]):\n",
    "    df_dict.setdefault(author_id, []).append(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "for author_ind, (author_id, texts) in enumerate(df_dict.items()):\n",
    "    author_path = f\"./blogtext/{author_ind}/\"\n",
    "    os.makedirs(os.path.dirname(author_path), exist_ok=True)\n",
    "\n",
    "    for text_ind, text in enumerate(texts):\n",
    "        text_path = f\"./blogtext/{author_ind}/{text_ind}.txt\"\n",
    "        with open(text_path, \"w\") as f:\n",
    "            f.write(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Gutenberg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pablo/.micromamba/envs/master-nlp/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"pg19\", split=\"train\", streaming=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt = next(iter(dataset))[\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4305731"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "txt = re.sub(r\"\\s+\", \" \", txt).strip()\n",
    "len(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "821144"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(txt.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The',\n",
       " 'Old',\n",
       " 'Testament',\n",
       " 'of',\n",
       " 'the',\n",
       " 'King',\n",
       " 'James',\n",
       " 'Version',\n",
       " 'of',\n",
       " 'the',\n",
       " 'Bible',\n",
       " 'The',\n",
       " 'First',\n",
       " 'Book',\n",
       " 'of',\n",
       " 'Moses:',\n",
       " 'Called',\n",
       " 'Genesis',\n",
       " '1:1',\n",
       " 'In',\n",
       " 'the',\n",
       " 'beginning',\n",
       " 'God',\n",
       " 'created',\n",
       " 'the',\n",
       " 'heaven',\n",
       " 'and',\n",
       " 'the',\n",
       " 'earth.',\n",
       " '1:2',\n",
       " 'And',\n",
       " 'the',\n",
       " 'earth',\n",
       " 'was',\n",
       " 'without',\n",
       " 'form,',\n",
       " 'and',\n",
       " 'void;',\n",
       " 'and',\n",
       " 'darkness',\n",
       " 'was',\n",
       " 'upon',\n",
       " 'the',\n",
       " 'face',\n",
       " 'of',\n",
       " 'the',\n",
       " 'deep.',\n",
       " 'And',\n",
       " 'the',\n",
       " 'Spirit',\n",
       " 'of',\n",
       " 'God',\n",
       " 'moved',\n",
       " 'upon',\n",
       " 'the',\n",
       " 'face',\n",
       " 'of',\n",
       " 'the',\n",
       " 'waters.',\n",
       " '1:3',\n",
       " 'And',\n",
       " 'God',\n",
       " 'said,',\n",
       " 'Let',\n",
       " 'there',\n",
       " 'be',\n",
       " 'light:',\n",
       " 'and',\n",
       " 'there',\n",
       " 'was',\n",
       " 'light.',\n",
       " '1:4',\n",
       " 'And',\n",
       " 'God',\n",
       " 'saw',\n",
       " 'the',\n",
       " 'light,',\n",
       " 'that',\n",
       " 'it',\n",
       " 'was',\n",
       " 'good:',\n",
       " 'and',\n",
       " 'God',\n",
       " 'divided',\n",
       " 'the',\n",
       " 'light',\n",
       " 'from',\n",
       " 'the',\n",
       " 'darkness.',\n",
       " '1:5',\n",
       " 'And',\n",
       " 'God',\n",
       " 'called',\n",
       " 'the',\n",
       " 'light',\n",
       " 'Day,',\n",
       " 'and',\n",
       " 'the',\n",
       " 'darkness',\n",
       " 'he']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt.split()[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
